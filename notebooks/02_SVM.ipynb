{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipynb\n",
    "import warnings\n",
    "from sklearn.exceptions import FitFailedWarning, ConvergenceWarning \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import statistics\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, RandomizedSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.utils._testing import ignore_warnings \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from ipynb.fs.full.preprocessing import preprocessing #import preprocessing class from preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#option 2: restore dataframes if previously stored in 00_EDA.ipynb\\n%store -r dwt8 \\ndwt8 = dwt8\\n\\n%store -r wp8\\nwp8 = wp8\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#option 1: call preprocessing class to generate dataframes\n",
    "prep_dwt = preprocessing(file_path = '/Users/jhbyun/Documents/685-Pr/ovarian-cancer-classification/data/DWT.csv') #initialize class for DWT_8702\n",
    "dwt = prep_dwt.label_df() #generate dataframe with labels\n",
    "\n",
    "prep_wang = preprocessing(file_path = '/Users/jhbyun/Documents/685-Pr/ovarian-cancer-classification/data/Wang.csv') #initialize class for WPD_Wang_8702\n",
    "wang = prep_wang.label_df()\n",
    "\n",
    "prep_jones = preprocessing(file_path = '/Users/jhbyun/Documents/685-Pr/ovarian-cancer-classification/data/Jones.csv') #initialize class for WPD_Wang_8702\n",
    "jones = prep_jones.label_df()\n",
    "\n",
    "\n",
    "'''\n",
    "#option 2: restore dataframes if previously stored in 00_EDA.ipynb\n",
    "%store -r dwt8 \n",
    "dwt8 = dwt8\n",
    "\n",
    "%store -r wp8\n",
    "wp8 = wp8\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (balanced sampling, default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(df, n_iter=1000):\n",
    "\n",
    "    df = df\n",
    "\n",
    "    subset_0 = df[df['state'] == 0]\n",
    "    subset_1 = df[df['state'] == 1]\n",
    "\n",
    "    subset_1 = subset_1.sample(n=91) #randomly sample cases to match number of controls\n",
    "    df = pd.concat([subset_0, subset_1])\n",
    "                     \n",
    "    x = df.loc[:, df.columns != 'state'] #features\n",
    "    y = df.loc[:, df.columns == 'state'] #supervisor\n",
    "\n",
    "    eval_metrics = { #empty dictionary to store classification report\n",
    "        '0_precision': [],\n",
    "        '0_recall': [],\n",
    "        '0_f1-score': [],\n",
    "        '0_support': [],\n",
    "\n",
    "        '1_precision': [],\n",
    "        '1_recall': [],\n",
    "        '1_f1-score': [],\n",
    "        '1_support': [],\n",
    "        \n",
    "        'accuracy': [],\n",
    "        'accuracy_train': [],\n",
    "    }\n",
    "\n",
    "    for i in range(n_iter): \n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.67)\n",
    "\n",
    "        scaler = StandardScaler()    \n",
    "        scaler.fit(x_train)\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "\n",
    "        svm_model = SVC()\n",
    "        svm_model.fit(x_train, y_train.values.ravel())\n",
    "        \n",
    "        y_pred = svm_model.predict(x_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "        y_pred_train = svm_model.predict(x_train)\n",
    "        report_train = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "\n",
    "        eval_metrics['0_precision'].append(report['0']['precision']) #store classification_report values in dictionary\n",
    "        eval_metrics['0_recall'].append(report['0']['recall'])\n",
    "        eval_metrics['0_f1-score'].append(report['0']['f1-score'])\n",
    "        eval_metrics['0_support'].append(report['0']['support'])\n",
    "\n",
    "        eval_metrics['1_precision'].append(report['1']['precision'])\n",
    "        eval_metrics['1_recall'].append(report['1']['recall'])\n",
    "        eval_metrics['1_f1-score'].append(report['1']['f1-score'])\n",
    "        eval_metrics['1_support'].append(report['1']['support'])\n",
    "\n",
    "        eval_metrics['accuracy'].append(report['accuracy'])\n",
    "        eval_metrics['accuracy_train'].append(report_train['accuracy'])\n",
    "\n",
    "    eval_metrics_df = pd.DataFrame.from_dict(eval_metrics) #convert dictionary to dataframe\n",
    "\n",
    "    return eval_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df_dwt = svm(dwt, n_iter=1000)\n",
    "acc_df_wang = svm(wang, n_iter=1000)\n",
    "acc_df_jones = svm(jones, n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWT Method Accuracy  0.942\n",
      "Wang Method Accuracy  0.9594\n",
      "Jones Method Accuracy  0.8771\n"
     ]
    }
   ],
   "source": [
    "print('DWT Method Accuracy ', round(acc_df_dwt['accuracy'].mean(), 4))\n",
    "print('Wang Method Accuracy ', round(acc_df_wang['accuracy'].mean(), 4))\n",
    "print('Jones Method Accuracy ', round(acc_df_jones['accuracy'].mean(), 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=(ConvergenceWarning, FitFailedWarning, UserWarning)) #ignore warnings for forbidden parameter combinations between solvers and penalty in grid\n",
    "\n",
    "def svm_search(df, n_iter = 100): \n",
    "\n",
    "    df = df\n",
    "\n",
    "    subset_0 = df[df['state'] == 0]\n",
    "    subset_1 = df[df['state'] == 1]\n",
    "\n",
    "    subset_1 = subset_1.sample(n=91) #randomly sample cases to match number of controls\n",
    "    df = pd.concat([subset_0, subset_1])\n",
    "\n",
    "    x = df.loc[:, df.columns != 'state'] #features\n",
    "    y = df.loc[:, df.columns == 'state'] #supervisor\n",
    "\n",
    "    eval_metrics = { #empty dictionary to store classification report\n",
    "        '0_precision': [],\n",
    "        '0_recall': [],\n",
    "        '0_f1-score': [],\n",
    "        '0_support': [],\n",
    "\n",
    "        '1_precision': [],\n",
    "        '1_recall': [],\n",
    "        '1_f1-score': [],\n",
    "        '1_support': [],\n",
    "        \n",
    "        'accuracy': [],\n",
    "        'accuracy_train': [],\n",
    "\n",
    "    }\n",
    "\n",
    "    for i in range(n_iter): \n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.67)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        svm_model = SVC()\n",
    "\n",
    "        param_grid = {\n",
    "            'svm__kernel': ['linear', 'rbf', 'poly'],\n",
    "            'svm__C':[1, 10, 100, 1000]\n",
    "        }\n",
    "\n",
    "\n",
    "        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1) \n",
    "        pipeline = Pipeline(steps=[(\"scaler\", scaler), (\"svm\", svm_model)])\n",
    "\n",
    "\n",
    "        search = RandomizedSearchCV(pipeline, param_grid, n_iter=50, scoring='accuracy', n_jobs=-1, cv=cv) #n_iter = number of parameter settings that are sampled\n",
    "        \n",
    "        result = search.fit(x_train, y_train.values.ravel())\n",
    "        y_pred = result.predict(x_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "        y_pred_train = result.predict(x_train)\n",
    "        report_train = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "\n",
    "        eval_metrics['0_precision'].append(report['0']['precision']) #store classification_report values in dictionary\n",
    "        eval_metrics['0_recall'].append(report['0']['recall'])\n",
    "        eval_metrics['0_f1-score'].append(report['0']['f1-score'])\n",
    "        eval_metrics['0_support'].append(report['0']['support'])\n",
    "\n",
    "        eval_metrics['1_precision'].append(report['1']['precision'])\n",
    "        eval_metrics['1_recall'].append(report['1']['recall'])\n",
    "        eval_metrics['1_f1-score'].append(report['1']['f1-score'])\n",
    "        eval_metrics['1_support'].append(report['1']['support'])\n",
    "\n",
    "        eval_metrics['accuracy'].append(report['accuracy'])\n",
    "        eval_metrics['accuracy_train'].append(report_train['accuracy'])\n",
    "\n",
    "    eval_metrics_df = pd.DataFrame.from_dict(eval_metrics) #convert dictionary to dataframe\n",
    "\n",
    "    return eval_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df_dwt = svm_search(dwt, n_iter=500)\n",
    "acc_df_wang = svm_search(wang, n_iter=500)\n",
    "acc_df_jones = svm_search(jones, n_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWT Method Accuracy  0.9259\n",
      "Wang Method Accuracy  0.9515\n",
      "Jones Method Accuracy  0.871\n"
     ]
    }
   ],
   "source": [
    "print('DWT Method Accuracy ', round(acc_df_dwt['accuracy'].mean(), 4))\n",
    "print('Wang Method Accuracy ', round(acc_df_wang['accuracy'].mean(), 4))\n",
    "print('Jones Method Accuracy ', round(acc_df_jones['accuracy'].mean(), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
