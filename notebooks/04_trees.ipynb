{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "from numpy import mean\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, GridSearchCV\n",
    "#from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "from ipynb.fs.full.preprocessing import preprocessing #import preprocessing class from preprocessing.ipynb\n",
    "from ipynb.fs.full.accuracy_plots import cumulative_accuracy_plot #import fx from accuracy_plots.ipynb\n",
    "from ipynb.fs.full.accuracy_plots import accuracy_by_nfeatures #import fx from accuracy_plots.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restore saved dataframes from 00_EDA.ipynb\n",
    "%store -r dwt_8 wang_8 jones_8\n",
    "dwt_8 = dwt_8\n",
    "wang_8 = wang_8\n",
    "jones_8 = jones_8\n",
    "\n",
    "%store -r dwt_topten_8 wang_topten_8 jones_topten_8\n",
    "dwt_topten_8 = dwt_topten_8\n",
    "wang_topten_8 = wang_topten_8\n",
    "jones_topten_8 = jones_topten_8\n",
    "\n",
    "%store -r dwt_4 wang_4 jones_4\n",
    "dwt_4 = dwt_4\n",
    "wang_4 = wang_4\n",
    "jones_4 = jones_4\n",
    "\n",
    "%store -r dwt_topten_4 wang_topten_4 jones_topten_4\n",
    "dwt_topten_4 = dwt_topten_4\n",
    "wang_topten_4 = wang_topten_4\n",
    "jones_topten_4 = jones_topten_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_forest(df, n_iter = 1000, balanced=False):\n",
    "\n",
    "    eval_metrics = { #empty dictionary to store classification report\n",
    "        '0_precision': [],\n",
    "        '0_recall': [],\n",
    "        '0_f1-score': [],\n",
    "        '0_support': [],\n",
    "\n",
    "        '1_precision': [],\n",
    "        '1_recall': [],\n",
    "        '1_f1-score': [],\n",
    "        '1_support': [],\n",
    "        \n",
    "        'accuracy': [],\n",
    "        'accuracy_train': [],\n",
    "    }\n",
    "    \n",
    "    for i in range(n_iter): \n",
    "\n",
    "        if(balanced == False):\n",
    "\n",
    "            subset_0 = df[df['state'] == 0]\n",
    "            subset_1 = df[df['state'] == 1]\n",
    "\n",
    "            subset_1 = subset_1.sample(n=91) #randomly sample cases to match number of controls\n",
    "            df = pd.concat([subset_0, subset_1])\n",
    "                     \n",
    "        x = df.loc[:, df.columns != 'state'] #features\n",
    "        y = df.loc[:, df.columns == 'state'] #supervisor\n",
    "\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.67)\n",
    "        \n",
    "        tree_model = RandomForestClassifier()\n",
    "        tree_model.fit(x_train, y_train.values.ravel())\n",
    "        y_pred = tree_model.predict(x_test)\n",
    "\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "        y_pred_train = tree_model.predict(x_train)\n",
    "        report_train = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "\n",
    "        eval_metrics['0_precision'].append(report['0']['precision']) #store classification_report values in dictionary\n",
    "        eval_metrics['0_recall'].append(report['0']['recall'])\n",
    "        eval_metrics['0_f1-score'].append(report['0']['f1-score'])\n",
    "        eval_metrics['0_support'].append(report['0']['support'])\n",
    "\n",
    "        eval_metrics['1_precision'].append(report['1']['precision'])\n",
    "        eval_metrics['1_recall'].append(report['1']['recall'])\n",
    "        eval_metrics['1_f1-score'].append(report['1']['f1-score'])\n",
    "        eval_metrics['1_support'].append(report['1']['support'])\n",
    "\n",
    "        eval_metrics['accuracy'].append(report['accuracy'])\n",
    "        eval_metrics['accuracy_train'].append(report_train['accuracy'])\n",
    "\n",
    "    eval_metrics_df = pd.DataFrame.from_dict(eval_metrics) #convert dictionary to dataframe\n",
    "\n",
    "    return eval_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWT Method Accuracy  0.9174\n",
      "Wang Method Accuracy  0.9422\n",
      "Jones Method Accuracy  0.8082\n"
     ]
    }
   ],
   "source": [
    "acc_dwt_8 = r_forest(dwt_topten_8, n_iter=10000)\n",
    "acc_wang_8 = r_forest(wang_topten_8, n_iter=10000)\n",
    "acc_jones_8 = r_forest(jones_topten_8, n_iter=10000)\n",
    "\n",
    "print('DWT Method Accuracy ', round(acc_dwt_8['accuracy'].mean(), 4))\n",
    "print('Wang Method Accuracy ', round(acc_wang_8['accuracy'].mean(), 4))\n",
    "print('Jones Method Accuracy ', round(acc_jones_8['accuracy'].mean(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWT Method Accuracy  0.8193\n",
      "Wang Method Accuracy  0.7765\n",
      "Jones Method Accuracy  0.8054\n"
     ]
    }
   ],
   "source": [
    "acc_dwt_4 = r_forest(dwt_topten_4, n_iter=10000, balanced=True)\n",
    "acc_wang_4 = r_forest(wang_topten_4, n_iter=10000, balanced=True)\n",
    "acc_jones_4 = r_forest(jones_topten_4, n_iter=10000, balanced=True)\n",
    "\n",
    "print('DWT Method Accuracy ', round(acc_dwt_4['accuracy'].mean(), 4))\n",
    "print('Wang Method Accuracy ', round(acc_wang_4['accuracy'].mean(), 4))\n",
    "print('Jones Method Accuracy ', round(acc_jones_4['accuracy'].mean(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratchpad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy by files and n Fisher's features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_forest_feat_accuracy_dwt = accuracy_by_nfeatures(class_instance=prep_dwt, file_name='DWT', classifier=r_forest, n_features=29, n_iter=500)\n",
    "r_forest_feat_accuracy_wang = accuracy_by_nfeatures(class_instance=prep_wang, file_name='Wang', classifier=r_forest, n_features=29, n_iter=500)\n",
    "r_forest_feat_accuracy_jones = accuracy_by_nfeatures(class_instance=prep_jones, file_name='Jones', classifier=r_forest, n_features=29, n_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_forest_feat_accuracy_dwt = r_forest_feat_accuracy_dwt.rename(\n",
    "                               columns = lambda col: f\"{col}_dwt\"\n",
    "                               if col not in ('n_features', 'file_name') else col)\n",
    "\n",
    "\n",
    "r_forest_feat_accuracy_wang = r_forest_feat_accuracy_wang.rename(\n",
    "                               columns = lambda col: f\"{col}_wang\"\n",
    "                               if col not in ('n_features', 'file_name') else col)\n",
    "\n",
    "\n",
    "r_forest_feat_accuracy_jones = r_forest_feat_accuracy_jones.rename(\n",
    "                               columns = lambda col: f\"{col}_jones\"\n",
    "                               if col not in ('n_features', 'file_name') else col)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge three dataframes on n_features\n",
    "merged_feat_accuracy_r_forest = r_forest_feat_accuracy_dwt.merge(r_forest_feat_accuracy_wang, how='right', on='n_features').merge(r_forest_feat_accuracy_jones, how='right', on='n_features')\n",
    "\n",
    "merged_feat_accuracy_r_forest.plot(\n",
    "           x='n_features',\n",
    "           y=['mean_dwt', 'mean_train_dwt', 'mean_wang', 'mean_train_wang', 'mean_jones', 'mean_train_jones'],\n",
    "           marker='.',\n",
    "           title='r_forest for DWT, Wang, and Jones Methods',\n",
    "           xlabel=\"Number of Selected Features by Fisher's Criterion\",\n",
    "           ylabel='Accuracy',\n",
    "           figsize=(10,5))\n",
    "\n",
    "plt.legend(['DWT Test', 'DWT Train', 'Wang Test', 'Wang Train', 'Jones Test', 'Jones Train'], loc='lower right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
